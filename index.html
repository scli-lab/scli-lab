
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Shengchao Li's lab</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Shengchao Li is currently a PI of Dark Matter and Neutrino Lab at Westlake University">
  <meta name="keywords" content="Shengchao Li, 李圣超, lishengchao, Shengchao, Dark Matter, Neutrino, XENONnT, Windchime">
  <meta name="author" content="Shengchao Li" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>XIHU</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#research" class="w3-bar-item w3-button">Research</a>
    <a href="#group members" class="w3-bar-item w3-button">Group Members</a>
    <a href="#publications" class="w3-bar-item w3-button">Publications</a>
    <a href="#events" class="w3-bar-item w3-button">Events</a>
    <a href="#join us" class="w3-bar-item w3-button">Join Us</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">XIHU</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/Shengchao_new.jfif">
      <h1>Shengchao Li</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
         Shengchao Li is an assistant professor in the School of Science at <a href="https://www.westlake.edu.cn/">Westlake University</a>. Shengchao was a postdoc in the <a href="https://www.physics.purdue.edu/darkmatters/">Dark Matter Group</a> at Purdue University, and a Ph.D. student in the <a href="https://cnp.phys.vt.edu/index.html">Center for neutrino physics</a> at Virginia Tech. He is a member of the XENONnT Experiment and the Windchime Project. He and his group are intersted in detecting dark matter and neutrinos through highly sensitive detectors, and study the physics beyond the Standard Model.
        </p>
        <p class="w3-center">
          <a href="mailto:lishengchao@westlake.edu.cn">Email</a> &nbsp/&nbsp
          <a href="https://en.westlake.edu.cn/faculty/shengchao-li.html">Department Website</a> &nbsp/&nbsp
          <a href="https://xenonexperiment.org/"> XENONnT Experiment </a> &nbsp/&nbsp
	  <a href="http://windchimeproject.org/"> Windchime Project </a> &nbsp/&nbsp
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> <a style="color:red">05/2023, Haven't updated in about one year. Some nice work has been done recently, and I will try to update more frequently</a>.</li></p>
      <p><li> 05/2023, I will give a talk about Multimodal Learning at <a href="http://valser.org/2023/#/workshopde?id=11">VALSE 2023 workshop</a>.</li></p>
      -->

  </div>
<!-- The Research Section -->
  <div class="w3-container w3-padding-32" id="research">
    <h2>Recent Research</h2>
    <p class="w3-justify">
        Actually, model compression is a kind of technique for developing portable deep neural networks with lower memory and computation costs. I have done several projects in Huawei including some smartphones' applications in 2019 and 2020 (e.g. Mate 30 and Honor V30). Currently, I am leading the AdderNet project, which aims to develop a series of deep learning models using only additions (<a href="https://www.reddit.com/r/MachineLearning/comments/ekw2s1/r_addernet_do_we_really_need_multiplications_in/">Discussions on Reddit</a>).
    </p>
	
	<h4><li>The Vanilla Neural Architecture for the 2020s</li></h4>
        <img style="width:96%;" src="images/VanillaNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/VanillaNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/abs/2305.12972">Paper</a> | <a style="color: #447ec9" href="https://www.zhihu.com/question/531529633/answer/3047230939">Discussion on Zhihu</a> 
        </p>
        <p class="w3-justify">
        <span style="color:red">VanillaNet is remarkable!</span> The concept was born from embracing the "less is more" philosophy in computer vision. It's elegantly designed by avoiding intricate depth and operations, such as self-attention, making it remarkably powerful yet concise. The 6-layer VanillaNet surpasses ResNet-34, and the 13-layer variant achieves about 83% Top-1 accuracy, outpacing the performance of networks with hundreds of layers, and revealing exceptional hardware efficiency advantages.
        </p> 
	 
        <h4><li>Adder Neural Networks</li></h4>
        <img style="width:96%;" src="images/AdderNet.jpg"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/AdderNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/pdf/2101.10015.pdf">Hardware Implementation</a>
        </p>
        <p class="w3-justify">
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        </p> 

        <h4><li>GhostNet on MindSpore: SOTA Lightweight CV Networks</li></h4>
        <img style="width:96%;" src="images/GhostNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://live.huawei.com/huaweiconnect/meeting/cn/5872.html">Huawei Connect (HC) 2020</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub">MindSpore Hub</a>
        </p>
        <p class="w3-justify">
        The initial verison of GhostNet was accepted by CVPR 2020, which achieved SOTA performance on ImageNet: <span style="color:red">75.7%</span> top1 acc with only <span style="color:red">226M FLOPS</span>. In the current version, we release a series computer vision models (e.g. int8 quantization, detection, and larger networks) on <strong>MindsSpore 1.0</strong> and <strong>Mate 30 Pro (Kirin 990)</strong>.
        </p> 

        <h4><li>AI on Ascend: Real-Time Video Style Transfer</li></h4>
        <img style="width:32%;" src="images/atlas200.png"> &nbsp&nbsp <img style="width:60%;" src="images/video.gif">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://www.huaweicloud.com/intl/en-us/HDC.Cloud.html">Huawei Developer Conference (HDC) 2020</a> | <a style="color: #447ec9" href="https://developer.huaweicloud.com/exhibition/Atlas_neural_style.html">Online Demo</a>
        </p>
        <p class="w3-justify">
        This project aims to develop a video style transfer system on the <strong>Huawei Atlas 200 DK AI developer Kit</strong>. The latency of the original model for processing one image is about <span style="color:red">630ms</span>. After accelerating it using our method, the lantency now is about <span style="color:red">40ms</span>. 
        </p>  

  </div>
  
  <!-- The Group Members -->
  <div class="w3-container w3-light-grey w3-padding-32" id="group members">
    <h2>Group Members</h2>
      <p><li> 12/2022, Hardware Efficient Deep Learning at <a href="https://ccf.org.cn/cncc2022/schedule_d_4179">China National Computer Congress (CNCC) 2022</a>. Thanks Prof. <a href="http://www.nlpr.ia.ac.cn/jcheng/">Jian Cheng</a> for the invitation.</li></p>
      <p><li> 05/2022, Low-Level Vision Transformer and Model Compression at <a href="https://2022.baai.ac.cn/">BAAI Conference 2022</a>. Thanks Prof. <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a> for the invitation.</li></p>
      <p><li> 10/2021, Vision Transformer at <a href="http://valser.org/2021/#/tutorial">VALSE 2021 Tutorial</a>. Thanks Prof. <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a> for the invitation.</li></p>
	  <p><li> 05/2021, Adder Neural Network at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>. Thanks <a href="https://datawisdom.ca/">Vahid Partovi Nia</a> for the invitation.</li></p>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/">VALSE Webinar.</li>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/">Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/">QbitAI</a>.</li></p>
  </div>
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Publications (* with corresponding authorship)</h2>
    
      
XENON Collaboration, 
      <p>
      <li> S. Li(XENON Collaboration); First Dark Matter Search with Nuclear Recoils from the XENONnT Experiment, Phys. Rev. Lett. 131, 041003 (2023)
      </p>
	  
      <p>
      <li><strong>S. Li* </strong>(XENON Collaboration); Searching for heavy dark matter near the Planck mass with XENON1T, <strong>Phys. Rev. Lett.</strong> 130 (2023) 26, 261002
      </p>

      <p>
      <li><strong>S. Li </strong>(XENON Collaboration); Search for New Physics in Electronic Recoil Data from XENONnT, <strong>Physical Review Letters,</strong> 2022, 129(16)
      </p>

      <p>
      <li><strong>S. Li </strong>(XENON Collaboration); Emission of single and few electrons in XENON1T and limits on light dark matter, <strong>Physical Review D,</strong> 2022, 106(2)
     </p>

      <p>
      <li>Awe, C.; Barbeau, P.; Haghighat, A.; Hedges, S.; Johnson, T.;<strong> Li, S.*</strong>; Link, J. M.; Mascolino, V; Runge, J.; Steenis, J.; Subedi, T.; Walkup, K.; Measurement of proton quenching in a plastic scintillator detector, <strong>JINST</strong>, 2021, 16(2)
     </p>

      <p>
      <li>Alireza Haghighat; Patrick Huber; <strong>Shengchao Li</strong>; Jonathan M. Link; Camillo Mariani; Jaewon Park; Tulasi Subedi; Observation of Reactor Antineutrinos with a Rapidly Deployable Surface- Level Detector, <strong>Physical Review Applied</strong>, 2020, 13(3)
     </p>

      <p>
      <li><strong>S. C. Li</strong> (Daya Bay Collaboration); Measurement of the Electron Antineutrino Oscillation with 1958 Days of Operation at Daya Bay,<strong> Physical Review Letters</strong>, 2018, 121(24)
     </p>

      <p>
      <li> <strong>S. C. Li </strong>(Daya Bay Collaboration); Evolution of the Reactor Antineutrino Flux and Spectrum at Daya Bay, <strong>Physical Review Letters</strong>, 2017, 118(25)
     </p>

      <p>
      <li><strong>S. C. Li</strong> (Daya Bay Collaboration); Measurement of the Reactor Antineutrino Flux and Spectrum at Daya Bay, <strong>Physical Review Letters</strong>, 2016, 116(6)
     </p>

      <p>
      <li></strong>S. C. Li</strong> (Daya Bay Collaboration); Improved Search for a Light Sterile Neutrino with the Full Configuration of the Daya Bay Experiment, Physical Review Letters, 2016, 117(15): 1-7
     </p>

      <p>
      <li><strong>S. C. Li </strong> (Daya Bay Collaboration); New Measurement of Antineutrino Oscillation with the Full Detector Configuration at Daya Bay, Physical Review Letters, 2015, 115(11)
     </p>

      </ol>

    </p>
  </div>

<!-- The Events Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="event">
    <h2>Events</h2>
      <p><li> Area Chair of <a href="https://nips.cc/Conferences/2023/">NeurIPS 2023</a>, <a href="https://icml.cc/Conferences/2023">ICML 2023</a>, <a href="https://nips.cc/Conferences/2022/">NeurIPS 2022</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Action Editor of <a href="https://jmlr.org/tmlr/">TMLR (Transactions on Machine Learning Research)</a>.</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
  </div>

  <!-- The Join Us Section -->
  <div class="w3-container w3-padding-32" id="join us">
    <h2>Join Us</h2>
      <p>
      <li><strong>博士后招聘</strong>
      <br>
       <strong>暗物质、中微子方向</strong>
      <br>
      招聘人数：1-2人<br>
      岗位职责:<br>
      1）加入XENONnT国际合作组，负责液氙探测器的运行和标定工作，领导组内其他成员模拟实验信号、分析实验数据，从而研究暗物质和新物理模型；<br>
      2）建设本地液态氙探测器和辅助设施，为暗物质和中微子研究进行创新和研发；<br>
      3）将前沿量子感应技术应用于暗物质的直接探测，设计并模拟量子加速度计阵列，并参与原型机设计建造。<br>
      应聘条件：<br>
      1）年龄不超过35周岁；已取得或即将取得粒子物理实验、核物理实验等相关领域博士学历；<br>
      2）熟悉液氙时间投影室技术 （优先考虑）；<br>
      3）熟悉量子感应及其信号处理（优先考虑）；<br>
      4）熟悉数据分析、模拟、统计等实验技术，并发表学术著作和学术报告。<br>
      </p>


  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a>.</br>
     <a style="color:red">Note: If you use this template, please remove the following code or replace it with your own counter!</a>.</br>

  <!-- Default Statcounter code for Yunhe Wang's Homepage
  https://www.wangyunhe.site -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2023. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
